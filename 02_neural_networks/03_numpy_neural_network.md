# Numpy를 이용한 신경망 기초 구현

## 1. 신경망의 기초적 구현 의의

Numpy만을 사용하여 신경망을 구현하는 것은 딥러닝의 내부 작동 원리를 이해하는 데 매우 유용합니다. TensorFlow나 PyTorch와 같은 고수준 라이브러리는 신경망 구현을 간소화하지만, 기본 개념의 이해를 위해서는 저수준 구현 경험이 중요합니다.

## 2. 활성화 함수와 그 미분

신경망에서 활성화 함수는 비선형성을 도입하여 복잡한 패턴을 학습할 수 있게 합니다.

### 2.1 시그모이드(로지스틱) 함수
- **정의:** `σ(x) = 1/(1+e^(-x))`
- **범위:** (0, 1)
- **용도:** 이진 분류 문제의 출력층
- **미분:** `σ'(x) = σ(x) * (1 - σ(x))`
- **특징:** 그래디언트 값의 최대치는 0.25로, 깊은 네트워크에서 그래디언트 소실 문제를 야기할 수 있음

### 2.2 하이퍼볼릭 탄젠트(Tanh) 함수
- **정의:** `tanh(x) = (e^x - e^(-x))/(e^x + e^(-x))` 또는 `tanh(x) = 2*σ(2x) - 1`
- **범위:** (-1, 1)
- **용도:** 은닉층 활성화 함수
- **미분:** `tanh'(x) = 1 - tanh^2(x)`
- **특징:** 출력이 평균적으로 0에 가까워(Zero-centered) 다음 층 학습에 유리

### 2.3 소프트맥스 함수
- **정의:** `softmax(x_i) = e^(x_i) / Σ_j e^(x_j)`
- **범위:** 각 요소는 (0, 1), 모든 요소의 합은 1
- **용도:** 다중 클래스 분류 문제의 출력층
- **특징:** 수치적 안정성을 위해 입력에서 최댓값을 빼는 기법 사용

## 3. 다중 작업 학습 (Multi-task Learning)

다중 작업 학습은 하나의 모델이 여러 관련된 작업을 동시에 학습하는 방법입니다.

### 3.1 장점
- 데이터 효율성 증가
- 특징 표현의 일반화 향상
- 작업 간 정보 공유로 성능 향상 가능

### 3.2 구현 방법
- 여러 작업에 대한 출력을 하나의 모델에서 생성
- 각 작업의 특성에 맞는 활성화 함수와 손실 함수 선택
- 전체 손실은 개별 작업 손실의 가중 합으로 계산

## 4. 손실 함수

각 작업의 특성에 맞는 손실 함수를 선택하는 것이 중요합니다.

### 4.1 제곱 오차 (Squared Error)
- **정의:** `SE(y, ŷ) = (y - ŷ)^2`
- **용도:** 회귀 문제

### 4.2 이진 교차 엔트로피 (Binary Cross-Entropy)
- **정의:** `BCE(y, ŷ) = -(y*log(ŷ) + (1-y)*log(1-ŷ))`
- **용도:** 이진 분류 문제

### 4.3 범주형 교차 엔트로피 (Categorical Cross-Entropy)
- **정의:** `CE(y, ŷ) = -Σ(y*log(ŷ))`
- **용도:** 다중 클래스 분류 문제

## 5. 신경망 학습 과정

### 5.1 순전파 (Forward Propagation)
1. 입력 데이터와 가중치, 편향을 사용해 선형 결합 계산: `Z = X @ W + B`
2. 각 작업에 맞는 활성화 함수 적용: `Y_pred = activation(Z)`

### 5.2 손실 계산
각 작업별로 적절한 손실 함수를 사용해 오차 계산

### 5.3 역전파 (Backpropagation)
1. 활성화 함수의 출력에 대한 손실의 그래디언트 계산
2. 체인 룰을 적용하여 가중치와 편향에 대한 그래디언트 계산
3. 경사 하강법을 사용해 파라미터 업데이트: `W -= lr * dL/dW`, `B -= lr * dL/dB`

### 5.4 단순화된 역전파
기본 개념 이해를 위한 간소화된 접근:
- `dL/dY_pred = Y_pred - Y` (손실 함수와 활성화 함수 미분의 조합)
- `W = W - lr * X.T @ dL/dY_pred`
- `B = B - lr * Σ(dL/dY_pred, axis=0)`

## 6. 코드 구현

실제 구현은 `multi_task_learning.py` 파일에서 확인할 수 있습니다. 
주요 구성 요소:
1. 라이브러리 임포트 및 기본 함수 정의
2. 학습 데이터 설정
3. 모델 초기화 (가중치, 편향)
4. 학습 루프 (순전파, 손실 계산, 역전파)
5. 학습 곡선 시각화
6. 학습된 모델로 예측 수행

## 7. 결론

Numpy를 활용한 신경망 구현은 다음과 같은 의의를 갖습니다:
- 딥러닝의 기본 원리와 수학적 개념 이해
- 모델 작동 방식에 대한 직관 형성
- 프레임워크에 의존하지 않는 유연한 사고 개발
- 다양한 활성화 함수와 손실 함수의 특성 및 용도 학습
