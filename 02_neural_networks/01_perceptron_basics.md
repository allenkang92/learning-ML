# 인공신경망(ANN) 기초 및 퍼셉트론

## 1. 퍼셉트론(Perceptron)의 기본 개념

- **구성 요소:**
    - **입력 (Inputs - X):** 외부에서 받아들이는 신호 또는 데이터 값 (x1, x2, ...)
    - **가중치 (Weights - W):** 각 입력 신호의 중요도를 나타내는 값 (w1, w2, ...)
    - **가중합 (Weighted Sum) / 선형합 (Linear Sum) / Affine:** 입력과 가중치의 곱들을 모두 더한 값
    - **편향 (Bias - B):** 뉴런(노드)이 얼마나 쉽게 활성화될지를 조절하는 값
        - 수식: `Affine = (x1*w1 + ... + xn*wn) + b = X @ W.T + B`
    - **활성화 함수 (Activation Function):** 가중합+편향 값을 입력받아 최종 출력 신호를 결정하는 함수
    - **출력 (Output - Y):** 활성화 함수를 통과한 최종 결과 값

## 2. 인공신경망(ANN)의 발전 과정

- **ANN (Artificial Neural Network):** 생물학적 신경망에서 영감을 받아 만들어진 계산 모델
- **SLP (Single Layer Perceptron - 단층 퍼셉트론):**
    - 입력층과 출력층만으로 구성
    - **한계:** 선형적으로 분리 가능한 문제만 해결 가능, **XOR 문제** 해결 불가
- **MLP (Multi Layer Perceptron - 다층 퍼셉트론):**
    - 입력층과 출력층 사이에 하나 이상의 **은닉층(Hidden Layer)** 추가
    - XOR 문제 해결 가능
- **DNN (Deep Neural Network - 심층 신경망):**
    - **많은** 은닉층을 가진 MLP로 복잡한 패턴 학습 가능
    - **발전 배경:** ReLU 활성화 함수, 하드웨어 발전, 개선된 학습 기법 등

## 3. 신경망의 작동 원리 (계산 과정)

- **선형 변환:** `Affine = X @ W.T + B`
- **활성화 함수:**
    - **Sigmoid:** 출력을 0과 1 사이 값으로 변환
    - **Softmax:** 출력을 확률 분포로 변환
    - **ReLU:** 입력이 양수면 그대로, 음수면 0 출력
    - **Step Function:** 임계값 기준 0 또는 1 출력
- **순전파:** 입력층에서 출력층까지 신호가 전달되며 예측값을 계산하는 과정

## 4. 신경망 학습 과정

- **목표:** 예측값과 실제 정답 간의 오차를 최소화하도록 가중치와 편향을 조정
- **손실 함수:** 오차를 측정하는 함수 (MSE, Cross-Entropy 등)
- **경사 하강법:** 손실 함수의 기울기를 계산하여 기울기가 낮아지는 방향으로 가중치 업데이트
    - **업데이트 규칙:** `W_new = W_old - learning_rate * (dL/dW)`
- **역전파 & 연쇄 법칙:** 오차를 역방향으로 전파시키며 각 층의 가중치에 대한 기울기 계산
- **학습률:** 가중치 업데이트 크기 조절하는 하이퍼파라미터
- **배치:** 데이터 처리 방식 (Full-batch, Stochastic, Mini-batch)
- **옵티마이저:** 경사 하강법을 개선한 알고리즘 (Momentum, Adam, RMSprop 등)
- **에포크:** 전체 데이터셋을 한 번 학습한 횟수

## 5. AND 게이트 구현 개념

1. **데이터셋 준비:** AND 연산의 입력(X)과 정답(Y) 정의
2. **모델 초기화:** 입력 2개, 출력 1개인 단층 퍼셉트론, 가중치(W)와 편향(B) 랜덤 초기화
3. **학습 과정:**
   - 순전파: 입력값으로 예측 계산 `pred_y = x @ W.T + B`
   - 손실 계산: 제곱 오차(SE) 사용 `loss = ((y - pred_y) ** 2).sum() / 2`
   - 역전파: 손실에 대한 가중치/편향의 기울기 계산
   - 가중치 갱신: 기울기와 학습률을 사용하여 가중치와 편향 업데이트
4. **모델 평가:** 학습된 가중치로 새로운 입력에 대한 AND 연산 결과 예측
5. **실제 구현은 `perceptron.py` 파일에서 확인 가능**
