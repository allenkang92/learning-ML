## 머신러닝/딥러닝 모델링, 표현 학습, 최적화, 모델 선택

### 1. 모델링의 본질과 현실적 접근

- **현실 모델링의 어려움:** 현실 세계는 복잡하여 완벽한 모델 구현은 불가능합니다. 따라서 현실을 **근사(Approximate)**하는 **모델링(Modeling)**이 필요합니다.
- **End-to-End vs. 모듈식 접근:**
    - **End-to-End:** 간단한 문제는 입력부터 출력까지 하나의 모델로 처리 가능.
    - **모듈식 (합성 함수):** 복잡한 문제는 여러 작은 모델로 쪼개어 조합 (분기 구조 가능, 콜백 모델 등 활용). 성공 보장성은 낮으나 현실적인 접근.
- **오컴의 면도날:** 같은 성능이라면 더 **단순한 모델**을 선호하는 원칙. 모델 선택의 기본 지침.

### 2. 표현 학습 (Representation Learning)의 중요성

- **핵심:** 데이터를 모델이 잘 이해하고 처리할 수 있는 **효과적인 형태(표현)**로 변환하는 학습 과정.
- **입력 데이터의 중요성:** 모델의 성능은 입력 데이터의 형태에 크게 의존. 입력 데이터의 특성을 잘 반영하는 표현을 학습하는 것이 중요.
- **차원 변경:** 표현 학습은 종종 데이터의 차원을 변경하는 방식으로 이루어짐 (차원 축소 또는 확장).
- **딥러닝과 표현 학습:**
    - **딥러닝의 강점:** 여러 계층(Layer)을 통해 데이터의 **계층적 표현(Hierarchical Representation)**을 자동으로 학습하는 능력.
    - **표현과 타입 (함수형 프로그래밍 관점):** 딥러닝의 '표현'은 함수형 프로그래밍의 '타입'과 유사. 각 레이어는 특정 '타입(표현)'의 데이터를 입력받아 다른 '타입(표현)'으로 변환. 타입(표현)이 맞아야 레이어 간 연결 가능.
    - **관계형 귀납 편향 (Relational Inductive Biases - DeepMind 논문):**
        - 현대 AI의 과제: **조합적 일반화(Combinatorial Generalization)** 능력 부족 (인간 지능의 핵심).
        - 해결책: 명시적인 **구조적 표현(Structured Representations)**과 **관계형 추론**을 위한 **귀납 편향**을 모델 설계에 반영. (End-to-End와 Hand-engineering의 조화).
        - **그래프 네트워크 (Graph Networks - GNs):** 개체(Node)와 관계(Edge)를 명시적으로 다루는 강력한 관계형 귀납 편향을 가진 딥러닝 빌딩 블록 제안. 기존 그래프 처리 모델(MPNN, NLNN 등) 통합 및 확장.
- **머신러닝의 3요소 (Pedro Domingos 논문):** 학습 = **표현(Representation)** + 평가(Evaluation) + 최적화(Optimization). 표현 방식 선택은 학습 가능한 가설 공간(Hypothesis Space)을 결정.
    - **다양한 표현 방식:** 인스턴스 기반(KNN, SVM), 초평면(NB, Logistic Regression), 결정 트리, 규칙 집합, 신경망, 그래픽 모델 등.

### 3. 최적화 (Optimization)

- **개념:** 모델 학습 과정 자체를 **최적화** 문제로 정의. 모델의 예측과 실제 정답 간의 **오차(Loss)를 최소화**하는 파라미터(가중치, 편향)를 찾는 과정.
- **Gradient Descent (경사 하강법):** 신경망, 퍼셉트론 등에서 손실 함수의 최솟값을 찾기 위해 가장 널리 사용되는 최적화 기법. 손실 함수의 기울기(Gradient)를 이용해 파라미터를 점진적으로 업데이트.
- **한계 및 대안:** 항상 최적해를 보장하지 않고(지역 최솟값), 수렴하지 않을 수도 있음. 따라서 모멘텀, Adam, RMSprop 등 다양한 **최적화 테크닉(Optimizer)** 존재.

### 4. 모델 선택 및 파인 튜닝 (Model Selection & Fine-tuning)

- **모델 선택:** 수많은 모델(Model Space) 중 **목적에 가장 적합한 모델**을 선정하는 과정. 논문 탐색, 코드 실행, 성능 비교/검증 필요. 선택 기준 명확화 및 후보 모델 준비 중요.
- **파인 튜닝:** 사전 학습된 모델을 **새로운 데이터나 태스크에 맞게 재학습**하는 기법. 가장 쉽고 효율적인 모델 활용 방법 중 하나.
    - **성공 조건:**
        - **모델 특성:** 단순하고 **범용적인(General)** 모델일수록 유리 (Ad-hoc 모델은 어려움). Transformer, CNN 기반 모델(BERT 등)은 비교적 용이.
        - **데이터 양:** 원본 학습 데이터 대비 **충분한 양**(보통 1/10 ~ 1/20 이상) 필요.
    - **어려움:** 파인 튜닝 자체가 어려울 수 있으며 성공 보장 없음. 논문/소스코드 통해 검증(Evaluation, Validation) 방법 확인 필수.

### 5. 과적합/과소적합 및 검증 (Overfitting/Underfitting & Validation)

- **과적합 (Overfitting):** 모델이 학습 데이터에만 너무 잘 맞춰져 새로운 데이터에 대한 **일반화 성능**이 떨어지는 현상. 학습을 오래 시키거나 데이터가 부족/편향될 때 발생. 모델 복잡도 증가 시 위험 커짐.
- **과소적합 (Underfitting):** 모델이 너무 단순하여 데이터의 패턴을 제대로 학습하지 못하는 현상. 모델 선택 오류 가능성.
- **검증 (Validation/Evaluation):** 모델의 일반화 성능을 객관적으로 평가하는 과정. **오버피팅 방지**에 필수.
    - **홀드아웃 (Hold-out):** 데이터를 학습/검증/테스트 세트로 분리. `train_test_split` 사용.
    - **교차 검증 (Cross-validation):** 데이터를 여러 번 나누어 학습/평가 반복.
    - **학습 곡선 (Learning Curve):** 학습 과정 중 손실/정확도 변화 시각화하여 오버/언더피팅 진단.

### 6. 특성 선택 (Feature Selection)

- **목적:** 모델 성능 향상, 계산 효율 증대, 과적합 방지를 위해 입력 특성 중 **중요한 특성만 선택**하는 기법.
- **방법:**
    - **임베디드 (Embedded):** 모델 학습 과정 자체에 특성 선택 포함 (예: Decision Tree의 `feature_importances_`, Lasso).
    - **필터 (Filter):** 통계적 방법으로 학습 전 특성 선택 (예: `chi2`, 상관계수). `SelectKBest` 사용.
    - **래퍼 (Wrapper):** 특정 모델을 사용하여 특성 부분집합의 성능을 반복적으로 평가하며 선택 (예: `RFE` - Recursive Feature Elimination). 계산 비용 높음.
- **차원 축소와의 차이:** 특성 선택은 **기존 특성 중 일부를 선택/제거**하는 반면, 차원 축소(PCA 등)는 **기존 특성을 조합하여 새로운 저차원 특성 공간으로 변환**.

### 7. 하이퍼파라미터 튜닝 (Hyperparameter Tuning)

- **하이퍼파라미터:** 모델 학습 과정에서 결정되지 않고 **사람이 직접 설정**해야 하는 값 (학습률, 배치 크기, k(KNN), 활성화 함수(ReLU, Sigmoid 등)).
- **튜닝:** 최적의 성능을 내는 하이퍼파라미터 조합을 찾는 과정. 딥러닝은 하이퍼파라미터가 많아 튜닝이 어렵고 모델의 Ad-hoc 성격을 강화하기도 함.
- **실습 (KNN):** `KNeighborsClassifier(k)`에서 `k`값을 3, 5, 7로 변경하며 성능 비교 후 최적의 `k=5`를 선택하는 과정 시연.

### 8. 기타 중요 사항 (Pedro Domingos 논문 요약)

- **일반화(Generalization)가 핵심:** 학습 데이터 성능만 보지 말고, 테스트 데이터 성능을 봐야 함.
- **데이터만으론 부족:** 학습에는 데이터 외 사전 지식/가정(Inductive Bias)이 반드시 필요 (No Free Lunch Theorem).
- **과적합의 다양한 측면:** Bias-Variance Trade-off 이해 중요. 강력한 학습기가 항상 좋은 것은 아님.
- **고차원의 저주:** 차원이 높아지면 직관이 통하지 않고, 데이터 부족 문제가 심화됨.
- **이론적 보장은 현실과 다름:** 실제 성능과 이론적 보장은 차이 큼. 이론은 이해와 설계의 원동력으로 활용.
- **특성 공학(Feature Engineering)이 핵심:** 가장 중요하고 많은 노력 소요. 도메인 지식 필요.
- **데이터 > 알고리즘:** 종종 더 많은 데이터가 더 똑똑한 알고리즘보다 효과적. (단, 확장성 고려).
- **단순성 != 정확성:** 오컴의 면도날은 정확성을 보장하지 않음. 단순함 자체로 가치 있음.
- **표현 가능 != 학습 가능:** 모델이 특정 함수를 표현 가능해도 실제 학습 가능성은 별개 문제.
- **상관관계 != 인과관계:** 머신러닝은 주로 상관관계를 학습. 인과관계 추론은 주의 필요.

---

**핵심 요약:**

- 현실 모델링은 **근사**와 **트레이드오프**의 과정이며, **표현 학습**과 **최적화**가 핵심 요소.
- 딥러닝은 강력하지만 **Ad-hoc** 성격과 **조합적 일반화**의 한계를 가질 수 있으며, **그래프 네트워크**와 같은 **관계형 귀납 편향**을 가진 모델이 대안으로 제시됨.
- 실제 모델 개발 시 **모델 선택, 파인 튜닝, 특성 선택, 하이퍼파라미터 튜닝** 등 다양한 **테크닉**이 중요하며, **과적합/과소적합**을 방지하기 위한 **검증** 과정이 필수적.
- 단순히 알고리즘만 보는 것이 아니라, **데이터의 중요성, 특성 공학, 일반화 성능, 모델의 해석 가능성** 등 다각적인 측면을 고려해야 성공적인 머신러닝 프로젝트를 수행할 수 있음.
