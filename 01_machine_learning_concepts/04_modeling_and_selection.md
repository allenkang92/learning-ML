## 머신러닝/딥러닝 모델링 및 선택

### 1. 현실 세계 모델링의 어려움과 접근 방식

- **현실 모델링의 복잡성:** 현실 세계의 문제를 완벽하게 반영하는 모델을 만드는 것은 매우 어렵습니다. 따라서 현실을 **근사(approximate)**하는 **모델링(Modeling)** 과정이 필요
- **End-to-End 모델 vs. 모듈식(Modular) 모델:**
    - **End-to-End:** 문제의 시작부터 끝까지 하나의 모델로 처리하는 방식. 내용이 단순하면 가능하지만, 복잡한 문제에는 데이터/리소스 소모가 크고 성공 보장성이 낮음
    - **모듈식 (합성 함수):** 복잡한 문제를 여러 개의 작은 문제로 나누어 각각의 모델을 만들고 이를 조합하는 방식. 단순히 순차적(a→b→c)이 아니라 분기(a→b1, a→c1) 등 복잡한 구조(콜백 모델 등 활용)를 가질 수 있음
- **오컴의 면도날 (Occam's Razor):** 같은 성능이라면 더 단순한 모델이 좋다는 원칙. 하지만 현실적인 제약으로 항상 가장 단순한 모델을 선택할 수는 없음

### 2. 모델 입력(Input)의 중요성

- **명확한 Input/Output:** 모델 설계 시 입력과 출력이 무엇인지 명확히 정의해야 함
- **Input 형태의 중요성:** 모델(`f(x)`)은 주어진 입력(x)을 받아 원하는 출력(정답)이 나오도록 파라미터를 조정하는 방식으로 학습됩니다. 따라서 **입력 데이터의 형태**가 모델 설계와 학습의 가장 중요한 시작점
- **모델 재사용 시 고려사항:** 다른 사람이 만든 모델을 가져올 때, 해당 모델이 학습된 데이터의 입력 형태와 내가 가진 데이터의 입력 형태가 다를 수 있음
    - **데이터 불일치:** 내 데이터를 모델이 학습된 데이터 형태처럼 **변환(전처리)**하는 과정이 필요 (모델 앞단에 전처리 추가)
    - **모델 재학습/새로 구축:** 전처리가 어렵거나 성능이 만족스럽지 않으면, 내 데이터에 맞게 모델을 **새로 만들거나 재학습(Fine-tuning)**해야 함

### 3. 현실적 제약과 타협

- **데이터 제약:** 현실의 모든 데이터를 사용할 수는 없으므로, **일부 데이터**로 모델을 만듭니다. 이 때문에 모델이 학습하지 않은 다른 데이터에 대해서는 성능이 저하될 수 있음(일반화 성능 문제)
- **사용자 경험 Trade-off:** 모델 성능 향상을 위해 입력을 많이 요구하면 사용자는 불편해질 수 있음. 데이터 수집 시 기술적/정책적 고려가 필요 (무분별한 수집 지양)
- **성능 vs. 단순성/시간:** 모델을 **단순화**하는 것이 좋지만(오컴의 면도날, 재학습 용이성), **성능**과 **학습/추론 시간**도 함께 고려해야 함
- **실현 가능성 테스트 (Feasibility Test):** 본격적인 개발 전, 아이디어나 모델이 현실적으로 구현 가능하고 효과가 있을지 검토하는 과정이 중요

### 4. 모델의 종류: General vs. Ad-Hoc

- **General Model (범용 모델):** 다양한 문제에 적용될 수 있는 일반적인 모델. 구조가 비교적 단순하며 **재학습/재교육(Fine-tuning)이 용이**
- **Ad-Hoc Model (특수 목적 모델):** 특정 문제 해결에 특화된 모델. 구조가 복잡할 수 있으며, 다른 문제에 적용하거나 재학습하기 어려울 수 있음
    - **딥러닝 모델:** 많은 딥러닝 모델, 특히 깊은 레이어를 가진 모델은 특정 문제에 매우 높은 성능을 보이지만 **Ad-hoc** 성격을 가지는 경우가 많습니다. 레이어가 많을수록 Specific 해지고, 적을수록 범용적 경향을 보임
    - **재학습 용이성:** Transformer, Convolution 기반 모델 (BERT 등)은 비교적 재학습이 잘 되는 편이나, 추천 시스템 등 특정 도메인 모델은 재학습이 어려울 수 있음
- **선택 기준:** 같은 성능이라면 간단한 모델(General)을 선택하는 것이 좋습니다 (오컴의 면도날)

### 5. 딥러닝에 대한 심층적 고찰

- **딥러닝의 현재 상태:** 매우 성공적이지만 아직 초기 단계이며, 통일된 이론보다는 성공적인 도구(신경망 구조) 중심으로 발전하는 **Ad-hoc** 상태일 가능성이 높음 (과거 생물 분류학, 화학처럼 미래에는 다른 관점에서 이해될 수 있음)
- **세 가지 주요 내러티브:** 신경과학(생물학적 유사성), 표현 학습(데이터 변환, 매니폴드 가설), 확률론(잠재 변수 모델)
- **새로운 관점 제안: 최적화와 함수형 프로그래밍의 연결**
    - 딥러닝의 핵심은 여러 **함수(레이어)를 합성(Composition)**하고, 이를 **최적화(Optimization)**하여 특정 작업을 수행하는 모델을 연구하는 것
    - **표현(Representations)은 타입(Types)과 같다:**
        - 각 레이어는 데이터를 특정 차원의 공간(Representation)으로 변환합니다. 이는 함수형 프로그래밍에서 데이터 타입을 정의하는 것과 유사
        - 레이어 간 연결은 표현(타입)이 일치해야 가능하며, 학습 과정에서 인접 레이어는 소통할 표현을 협상
        - 복잡한 아키텍처(다중 입/출력 등)에서 이는 중요한 제약 조건이자 강력한 기능(다른 종류 데이터 통합, 번역, 제로샷 학습 등)의 기반이 됨
    - **신경망 패턴은 고차 함수(Higher-Order Functions)와 같다:**
        - 하나의 뉴런(함수)을 여러 곳에서 재사용하는 것(Weight Tying)은 함수형 프로그래밍의 함수 추상화와 유사하며, 딥러닝의 핵심 성공 요인
        - RNN (순환 신경망): 인코딩 RNN = `fold`, 생성 RNN = `unfold`, 일반 RNN = `mapAccum`, 양방향 RNN = `zip(mapAccumL, mapAccumR)`
        - CNN (합성곱 신경망): `map`과 유사하나 이웃까지 고려하는 "Windowed Map"
        - Recursive NN (TreeNet): `catamorphism` (트리 구조 처리)
    - **미분 가능한 함수형 프로그래밍 (Differentiable Functional Programming):**
        - 딥러닝 모델은 고차 함수 구조 안에 학습 가능한 요소(신경망 청크)를 넣어, 전체 프로그램을 데이터 기반으로 **미분(경사 하강법)**을 통해 최적화하는 방식
        - 이를 통해 직접 만들기 어려운 복잡한 프로그램(이미지 캡셔닝 등) 생성이 가능해짐
- **결론:** 딥러닝을 최적화와 함수형 프로그래밍의 아름다운 교차점으로 보는 것은 매우 흥미롭고 그럴듯한 관점이며, 미래에 딥러닝을 이해하는 방식이 될 수 있음

### 6. 모델 선택 (Model Selection)

- **정의:** 수많은 모델이 존재하는 **모델 스페이스(Model Space)**에서 **내 목적에 가장 적합한 모델**을 탐색하고 선정하는 과정
- **과정:** 다양한 모델(논문, 코드)을 탐색하고, 후보 모델들을 비교/검증하여 최종 모델 선택 (선택 기준 명확화 중요)
- **검증:** 선택된 모델이 실제로 잘 작동하는지 평가하는 과정 (검증 방안 수립 필요)

### 7. 파인 튜닝 (Fine-tuning)

- **정의:** 기존에 학습된 모델을 **내 데이터나 목적에 맞게 재학습/재교육**하는 과정
- **조건:**
    - 모델 복잡도: **단순하고 범용적인 모델**일수록 파인 튜닝이 잘 됩니다 (Ad-hoc 모델은 어려움)
    - 데이터 양: 내가 가진 데이터가 **충분히 많을수록** (원래 모델 학습 데이터의 1/10 ~ 1/20 이상) 파인 튜닝 성공 가능성이 높음
- **주의:** 모든 모델이 파인 튜닝 가능한 것은 아니며, 성공을 보장할 수도 없음

### 8. 학습 시 문제점 및 해결

- **언더피팅 (Underfitting):** 모델이 너무 단순하거나 학습이 부족하여 데이터의 패턴을 제대로 학습하지 못하는 경우 (모델 재선택, 학습 추가 진행 필요)
- **오버피팅 (Overfitting):** 모델이 학습 데이터에 너무 과도하게 최적화되어, 새로운 데이터에 대한 일반화 성능이 떨어지는 경우 (모델 단순화, 규제(Regularization), 데이터 증강 등 필요)
    - 오버피팅이 더 심각한 문제인 경우가 많음
    - 데이터 부족 또는 모델과 데이터 불일치가 원인일 수 있음
- **진단:** **학습 곡선(Learning Curve)**을 그려보며 오버피팅/언더피팅 여부 판단 가능
- **테스트 중요성:** 실제 테스트 데이터를 사용해보기 전까지는 오버피팅/언더피팅 발생 여부를 확신하기 어려움

### 9. 하이퍼파라미터 튜닝 (Hyperparameter Tuning)

- **파라미터 (Parameter):** 모델이 학습 과정에서 **데이터로부터 스스로 학습하는 값** (예: 가중치 W, 편향 B)
- **하이퍼파라미터 (Hyperparameter):** 모델이 학습할 수 없어 **사람이 직접 설정**해주어야 하는 값 (예: 학습률(lr), 배치 크기, 은닉층 수, KNN의 k값 등)
    - 딥러닝 모델은 하이퍼파라미터가 매우 많아 튜닝이 어렵고, 이로 인해 Ad-hoc 성격이 강해지기도 합니다
- **튜닝 과정:** 다양한 하이퍼파라미터 조합을 시도하여 최적의 성능을 내는 조합을 찾는 과정 (보통 5~10% 성능 개선 기대)
    - 깃허브 등의 `configs` 디렉토리에 튜닝 관련 설정이 있는 경우가 많습니다

### 10. 통계적 모델링의 두 가지 문화 (Two Cultures)

- **데이터 모델링 (Data Modeling):** 주로 통계학 기반. **설명력** 중시. 주어진 모델 구조 하에서 **파라미터 추정**에 집중 (끼워맞추기식)
- **알고리즘 모델링 (Algorithmic Modeling):** 주로 머신러닝/딥러닝 기반. **예측 성능** 중시. 데이터로부터 **모델 구조 자체를 찾아가는** 경향 (맞춤형). 구조 탐색이 매우 어렵지만 성능이 우수할 수 있음. 설명이 어려울 수 있음

### 11. 실습: KNN을 이용한 와인 분류 및 모델 선택 (Scikit-learn)

- **목표:** 와인 데이터를 이용하여 품종 분류. 최적의 KNN 모델(하이퍼파라미터 k) 선택
- **데이터 로드:** `load_wine` 데이터셋 사용
- **데이터 분할:** `train_test_split` 함수 사용. 학습 데이터(train)와 평가 데이터(test) 분리 (**홀드아웃 검증**). 모델의 일반화 성능을 객관적으로 평가하기 위함
- **모델 선택 및 초기화:** KNN 분류기 선택 (오컴의 면도날 고려). 하이퍼파라미터 `k`를 3, 5, 7로 다르게 설정한 모델 3개 생성
- **모델 학습:** 각 모델을 학습 데이터(`X_train`, `y_train`)로 학습(fit)
- **모델 평가:** 학습된 각 모델을 테스트 데이터(`X_test`, `y_test`)로 평가(score - 정확도 측정)
- **하이퍼파라미터 선택:** k=5일 때 정확도(0.733)가 가장 높으므로, `knn5` 모델을 최종 선택. 이 과정이 **하이퍼파라미터 튜닝/선택**에 해당

---

**핵심 요약:**

- 현실 모델링은 복잡하며, End-to-End 방식보다는 **모듈식 접근**이 현실적인 경우가 많다.
- 모델의 **입력 형태**는 매우 중요하며, 모델 재사용 시 **전처리**나 **파인 튜닝**이 필요할 수 있다.
- 딥러닝은 강력하지만 **Ad-hoc** 성격이 강하며, **함수형 프로그래밍** 관점에서 이해하려는 시도도 있다.
- **모델 선택**은 목적에 맞는 최적의 모델을 탐색/검증하는 과정이며, **파인 튜닝**은 기존 모델을 재활용하는 방법.
- **오버피팅/언더피팅** 문제를 인지하고 **학습 곡선** 등으로 진단하며, **하이퍼파라미터 튜닝**을 통해 모델 성능을 개선해야 한다.
- **홀드아웃 검증**(데이터 분할)은 모델의 일반화 성능을 객관적으로 평가하는 필수 과정.
